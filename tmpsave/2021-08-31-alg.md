# 一些分析

用[和最佳算法的比](https://en.wikipedia.org/wiki/Competitive_analysis_(online_algorithm))来衡量在线算法

https://link.springer.com/content/pdf/10.1007/PL00009192.pdf



多核paging的讨论

[无法找到跟最佳实践的比的常数上界](https://dl.acm.org/doi/pdf/10.1145/3350755.3400270)



> lt: 大致意思是每个任务有些可以频繁命中设为easy，而有些不能就需要频繁换入设为hard。那么可以通过认为延迟一点其中一个队列(优先踢出easy的页)，达到错开不同队列的访问的目的，让cache尽量多得为hard的部分服务，达到尽量减少pf的目的。
>
> 算到核数大于等于2的时候，下确界为n1/2/k,  因此常数下界是不存在的。（n是读页总次数，k是本地内存（或者说cache）量）
>
> 但是感觉这样easy也可能会变成hard？
>
> 不过转换下思维，尽量让时间局部性比较强的部分获取更多的缓存页确实是可以加速。也许确实是可以比直接竞争好。
>
> 比如说cache为4，有两个不同进程的访问序列a:{1，2，3，1，2，3，1，2，3，。。。}，b:{1，2，3，4，5，6，7，。。。}
>
> 那么如果显然给a序列3个缓存，而b序列1个将可以让缺页数等于b的序列长。
>
> 但是如果是竞争的话，两个都要频繁换入换出
>
> 缺页比为**(|a|+|b|) / |b|** 。性能差得还是有点远的。



[Paging for Multi-Core Shared Caches](https://dl.acm.org/doi/pdf/10.1145/2090236.2090246)

详细描述了可能，提出很难跟最佳算法比。建议找别的参照。





大多数都是demand paging。

事实上linux kernel的预取虽然通过预取大幅度减少了传输延迟的等待时间，但是都是放到swapcache中，这将导致在需要的时候，仍然需要2us+的时间来加入到mem中。而事实上读一个页进来也就2us（从发完请求到传输完成，页面解锁）。这样的话实际上仍然需要较多时间，跟demand paging实际上应该可以算是一样的。



而我们的换页其实也差不多。不过因为直接放进mem里面而不是先放到swapcache，所以对替换算法的压力可能会更大（？swapcache无限制？，不过确实没找到哪里限制了swapcache。。）

------

# 模型

暂时不考虑网络带宽带来的延迟影响。（因为根据盘海洋的测算带宽大概都是1Gbps以下，就算是50%的正确率，也只需要2Gbps的带宽，对于正常的应用来说，用处不是很大）

1. 每个进程或者线程的访存行为表示为若干序列{$$x_0^p$$ , ... , $$x_i^p$$}，表示进程p的0~i个访存行为。假设序列间的访问间隔是相等的。每个访存为页

2. 需要的内存量为N=$$\sum_{i}^p{N_i^p}$$
3. 本地内存总量为M，延迟为$$L_{mem}$$
4. 远端内存（二级）总量不限,  延迟为$$L_{remote}$$
5. 标记缺页率为$$R_{miss}$$
6. 




$$
MIN(AVG(latency)) \\
latency = L_{mem}+R_{miss}L_{remote}
$$


换页算法应该分成两部分

预取算法

替换算法

~~放置算法~~（现在在内存，没必要连续什么的，就不需要了）



可以通过替换算法的改动，达到调度的目的。。。

------

参数

假设

先假设



|                  |      |      |          |
| ---------------- | ---- | ---- | -------- |
| 总带宽           |      |      |          |
| 剩余带宽         |      |      |          |
| 本地内存总量     |      |      |          |
| 每个进程的内存量 |      |      |          |
| 每个进程的局部性 |      |      | 不好描述 |
|                  |      |      |          |
|                  |      |      |          |



------